{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Task\n",
    "\n",
    "Your task is focused on data processing, visualisation and basic statistical analysis. You will be asked to:\n",
    " 1. [basic] download publically available data of chemical compounds\n",
    " 1. [basic] do basic cleaning/processing\n",
    " 1. [basic] visualise and compute correlation between experimental and heuristic features\n",
    " 1. [intermediate] use kernel techniques to visualise the data in 2D\n",
    " 1. [advanced] make the approach more efficient so it can run in a few seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## General rules\n",
    "\n",
    "Use only basic python libraries, i.e.: `matplotlib, sklearn, numpy, scipy, csv, pandas, seaborn`.\n",
    "\n",
    "You can write your solution either directly in colab, or in your favourite IDE. Once you are finished, copy it to colab and make sure it runs with the standard free kernel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2665145296.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  File \u001B[0;32m\"/var/folders/vj/0q3kwzrj25q2nxq4gt9d0z1r0000gn/T/ipykernel_48795/2665145296.py\"\u001B[0;36m, line \u001B[0;32m3\u001B[0m\n\u001B[0;31m    Use only basic python libraries, i.e.: `matplotlib, sklearn, numpy, scipy, csv, pandas, seaborn`.\u001B[0m\n\u001B[0m        ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## [Task 1] [Basic] Gather data\n",
    "\n",
    "Your first task is to navigate to the ChEMBL database (https://www.ebi.ac.uk/chembl/), one of the biggest datasbases of bioactive molecules, and find an **assay** from AstraZeneca entitled \"*Octan-1-ol/water (pH7.4) distribution coefficent measured by a shake flask method*\". It is a result of an experiment measuring said property (often called \"logD\" for 4200 compounds).\n",
    "\n",
    "Download this data as a .csv format (by clicking \"ChEMBL Activity Types for Assay\" button in the Bioactivity section of the assay), as well as data for \"Associated Compounds for Assay\" which you will find on the assay's website, in the section called \"Compound Summary\". Lets call these files \"astrazeneca.csv\" and \"compounds.csv\" respectively.\n",
    "\n",
    "If you are using colab, you can upload these files to your kernel by\n",
    "\n",
    "```\n",
    "from google.colab import files\n",
    "files.upload()\n",
    "\n",
    "with open(\"astrazeneca.csv\") as fh:\n",
    "  # process your file\n",
    "  pass\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## [Task 2] [Basic] [Data processing]\n",
    "\n",
    "Merge the two datasets, using 'Smiles' as a key.\n",
    "Keep all the data from 'compounds.csv' apart from 'CX Basic pKa' and 'CX Acidic pKa', but only extract 'Standard Value' from each entry in 'astrazeneca.csv' and add it as \"Experimental Value\" in your resulting dataset.\n",
    "If you encounter multiple entries with the same Smiles, average the corresponding experimental values. For every entry that can be converted to a float, convert it and keep remaining entries as strings.\n",
    "\n",
    "Investigate your dataset, are there any entries that are missing some features? Remove compounds that are missing any numerical values.\n",
    "\n",
    "After this process you should remove 11 molecules, and thus end up with the dataset of 4,187.\n",
    "\n",
    "If you were to sort it alphabetically by the key, and print the first element you should see something along the lines of\n",
    "\n",
    "```\n",
    "{'ChEMBL ID': 'CHEMBL108667',\n",
    " 'Name': '',\n",
    " 'Synonyms': '',\n",
    " 'Type': 'Small molecule',\n",
    " 'Max Phase': 0.0,\n",
    " 'Molecular Weight': 454.21,\n",
    " 'Targets': 6.0,\n",
    " 'Bioactivities': 7.0,\n",
    " 'AlogP': 4.37,\n",
    " 'Polar Surface Area': 24.5,\n",
    " 'HBA': 3.0,\n",
    " 'HBD': 1.0,\n",
    " '#RO5 Violations': 0.0,\n",
    " '#Rotatable Bonds': 6.0,\n",
    " 'Passes Ro3': 'N',\n",
    " 'QED Weighted': 0.7,\n",
    " 'CX LogP': 4.65,\n",
    " 'CX LogD': 2.83,\n",
    " 'Aromatic Rings': 2.0,\n",
    " 'Structure Type': 'MOL',\n",
    " 'Inorganic Flag': -1.0,\n",
    " 'Heavy Atoms': 24.0,\n",
    " 'HBA (Lipinski)': 3.0,\n",
    " 'HBD (Lipinski)': 1.0,\n",
    " '#RO5 Violations (Lipinski)': 0.0,\n",
    " 'Molecular Weight (Monoisotopic)': 452.0099,\n",
    " 'Molecular Species': 'BASE',\n",
    " 'Molecular Formula': 'C19H22Br2N2O',\n",
    " 'Smiles': 'Brc1cc(Br)cc(COC[C@H](c2ccccc2)N2CCNCC2)c1',\n",
    " 'Experimental Value': 2.8}\n",
    " ```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## [Task 3] [Basic] Visualisation and correlation analysis\n",
    "\n",
    "All the values coming from our compounds.csv file are either basic properties of the molecule, or come from some heuristic calculations. We want to analyse how related they are to the experimentally measured values.\n",
    "\n",
    "Plot the pairwise correlations between every numeric property present in the data and the \"Experimental Value\". Additionally, compute the Pearson correlation coefficient.\n",
    "\n",
    "**QUESTION: Which of the features has the strongest positive correlation? What about the strongest negative correlation?**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## [Task 4] [Intermediate] 2D data visualisation with kernel methods\n",
    "\n",
    "There are many ways in which we could try to visualise our dataset of molecules. We will focus on Kernel PCA, that we will apply directly to the string representation of the molecule (Smiles).\n",
    "\n",
    "Let us define a kernel for the substrings of length $m$ as\n",
    "\n",
    "$$\n",
    "K_m(s_1, s_2) = \\sum_{w: |w|=m} \\left [ count(s_1, w) \\cdot count(s_2, w) \\right ]\n",
    "$$\n",
    "\n",
    "where $w$ is any word of length $m$, and $count(s, w)$ checks how many times word $w$ occures in $s$ as a consecutive substring with overlaps (note that `s.count(w)` ignores overlaps!). For example for\n",
    "\n",
    "$$\n",
    "s=\\texttt{Brc1cc(Br)cc(COC[C@H](c2ccccc2)N2CCNCC2)c1}\n",
    "$$\n",
    "\n",
    "we have\n",
    "$$\n",
    "count(s, \\texttt{C}) = 7\\;\\; count(s, \\texttt{cc}) =6\\;\\;count(s, \\texttt{ccc}) = 3\n",
    "$$\n",
    "\n",
    "For example\n",
    "\n",
    "$$\n",
    "K_1(\\texttt{tree}, \\texttt{apple}) = \\sum_{w \\in \\{ \\texttt{t,r,e}\\} } count(\\texttt{tree}, w) \\cdot count( \\texttt{apple}, w) = 1 \\cdot 0 + 1 \\cdot 0 + 2 \\cdot 1 = 2\n",
    "$$\n",
    "\n",
    "Using this definition of the kernel, compute the Kernel (Gram) matrix $G$, such that\n",
    "\n",
    "$$\n",
    "G^m_{ij} = K_m(s_i, s_j)\n",
    "$$\n",
    "\n",
    "where $s_i$ is $i$th Smiles in the lexicographic order, for $m=1$ and $m=2$.\n",
    "\n",
    "After doing so, you can use scikit-learn KernelPCA to create a 2D embedding\n",
    "\n",
    "```\n",
    "from sklearn.decomposition import KernelPCA\n",
    "embedding = KernelPCA(kernel='precomputed').fit_transform(G)\n",
    "```\n",
    "\n",
    "Use this embedding to plot your dataset, and use each of the features to colour your points. **Which of the features can be seen to be highly correlated with this embedding space?**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## [Task 5] [Advanced] Scaling up\n",
    "\n",
    "In total, there are 33 symbols used in Smiles strings. Consequently there are $33^m$ words of length $m$.\n",
    "We have around 4,000 compounds and thus around 16,000,000 entries in the kernel matrix to be computed.\n",
    "Even if we were to assume that the count() function is constant time, a naive algorithm of the form\n",
    "\n",
    "    kernel = np.zeros((len(smiles), len(smiles))\n",
    "    for i1, s1 in enumerate(smiles):\n",
    "      for i2, s2 in enumerate(smiles):\n",
    "        score = 0\n",
    "        for w in words_generator(m):\n",
    "          score += count(s1, w) * count(s2, w)\n",
    "        kernel[i1, i2] = score\n",
    "\n",
    "will take a prohibitive amount of time as $m$ grows:\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}